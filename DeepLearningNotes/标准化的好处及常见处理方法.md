## 数据的标准化、归一化
在多指标评价体系中，由于各评价指标的性质不同，通常具有不同的量纲和数量级。当各指标间的水平相差很大时，如果直接用原始指标值进行分析，就会突出数值较高的指标在综合分析中的作用，相对削弱数值水平较低指标的作用。因此，为了保证结果的可靠性，需要对原始指标数据进行标准化处理。

数据的标准化（normalization）是将数据按比例缩放，使之落入一个小的特定区间。在某些比较和评价的指标处理中经常会用到，去除数据的单位限制，将其转化为无量纲的纯数值，便于不同单位或量级的指标能够进行比较和加权。


#### 归一化的目标

1. **把数变为（0，1）之间的小数**
主要是为了数据处理方便提出来的，把数据映射到0～1范围之内处理，更加便捷快速，应该归到数字信号处理范畴之内。
2. **把有量纲表达式变为无量纲表达式**
归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量。 比如，复数阻抗可以归一化书写：Z = R + jωL = R(1 + jωL/R) ，复数部分变成了纯数量了，没有量纲。

#### 归一化的好处

**1. 提升模型的收敛速度**

如下图，x1的取值为0-2000，而x2的取值为1-5，假如只有这两个特征，对其进行优化时，会得到一个窄长的椭圆形，导致在梯度下降时，梯度的方向为垂直等高线的方向而走之字形路线，这样会使迭代很慢，相比之下，右图的迭代就会很快（理解：也就是步长走多走少方向总是对的，不会走偏）
![image1](https://github.com/liuchuanloong/AI-Notes/blob/master/picture/pic20191024/pic20191024001.png)

**2.提升模型的精度**

归一化的另一好处是提高精度，这在涉及到一些距离计算的算法时效果显著，比如算法要计算欧氏距离，上图中x2的取值范围比较小，涉及到距离计算时其对结果的影响远比x1带来的小，所以这就会造成精度的损失。所以归一化很有必要，他可以让各个特征对结果做出的贡献相同。

从经验上说，归一化是让不同维度之间的特征在数值上有一定比较性，可以大大提高分类器的准确性。

**3. 深度学习中数据归一化可以防止模型梯度爆炸。**

#### 常用的标准化方法

目前数据标准化方法有多种，归结起来可以分为直线型方法(如极值法、标准差法)、折线型方法(如三折线法)、曲线型方法(如半正态性分布)。不同的标准化方法，对系统的评价结果会产生不同的影响，然而不幸的是，在数据标准化方法的选择上，还没有通用的法则可以遵循。常见的方法有：min-max标准化（min-max normalization）、log函数转换、atan函数转换、z-score标准化（zero-mena normalization，此方法比较常用）、模糊量化法。

**min-max标准化(min-max normalization)也叫离差标准化**，是对原始数据的线性变换，使结果落到[0,1]区间，转换函数如下:其中max为样本数据的最大值，min为样本数据的最小值。这种方法有一个缺陷就是当有新数据加入时，可能导致max和min的变化，需要重新定义。

**log函数转换**是通过以10为底的log函数转换以实现归一下，具体方法如下:**y=log10(x)/log10(max)，max为样本数据最大值，并且所有的数据都要大于等于1**。

**atan函数转换**用反正切函数实现数据的归一化:需要注意的是如果想使用这个方法映射到[0,1]的区间，则数据都应该大于等于0，小于0的数据将被映射到[-1,0]区间上。

当然并非所有数据标准化的结果都需要映射到[0,1]区间上，这时就可以使用**z-score标准化方法**，该方法是SPSS中最为常用的标准化方法:z-score 标准化(zero-mean normalization)**也叫标准差标准化**，**该方法使得经过处理的数据符合标准正态分布，即均值为0，标准差为1，其转化函数为:y=(x−μ)/σ，其中μ为所有样本数据的均值，σ为所有样本数据的标准差**。

下面介绍三种最常用的标准化方法：min-max法（规范化方法），z-score法（正规化方法），比例法。

**（1）最小-最大规范化**
最小-最大规范化也称为离散标准化，是对原始数据的线性变换，将数据值映射到[0, 1]之间。
转换公式如下：

![image2](https://github.com/liuchuanloong/AI-Notes/blob/master/picture/pic20191024/pic20191024002.png)


离差标准化保留了原来数据中存在的关系，是消除量纲和数据取值范围影响的最简单方法。这种处理方法的缺点是若数值集中且某个数值很大，则规范化后各值接近于0，并且将会相差不大。（如 1， 1.2， 1.3， 1.4， 1.5， 1.6，8.4）这组数据。若将来遇到超过目前属性[min, max]取值范围的时候，会引起系统报错，需要重新确定min和max。

**（2）零-均值规范化（z-score标准化）**
零-均值规范化也称标准差标准化，经过处理的数据的均值为0，标准差为1。转化公式为：

![image3](https://github.com/liuchuanloong/AI-Notes/blob/master/picture/pic20191024/pic20191024003.png)

其中<img src="https://latex.codecogs.com/gif.latex?\overline{x}" title="\overline{x}" />为原始数据的均值，<img src="https://latex.codecogs.com/gif.latex?\sigma" title="\sigma" />为原始数据的标准差，是当前用得最多的数据标准化方式。标准差分数可以回答这样一个问题："给定数据距离其均值多少个标准差"的问题，在均值之上的数据会得到一个正的标准化分数，反之会得到一个负的标准化分数。
**z-score标准化方法适用于属性A的最大值和最小值未知的情况，或有超出取值范围的离群数据的情况**。

**（3）比例法（归一化方法）**

![image4](https://github.com/liuchuanloong/AI-Notes/blob/master/picture/pic20191024/pic20191024004.png)

注意该方法是针对全部数据为**正值**的序列。

**参考**

[数据规范化（归一化）、及Z-score标准化](https://blog.csdn.net/weixin_38706928/article/details/80329563)

[数据标准化的三种最常用方式总结（归一化）](https://blog.csdn.net/jisuanjiguoba/article/details/86439375)

[数据标准化/归一化normalization](https://blog.csdn.net/pipisorry/article/details/52247379)

[归一化的好处及归一化，标准化的处理方法](https://blog.csdn.net/weixin_38313518/article/details/79950654)

[GitHub](https://github.com/liuchuanloong/AI-Notes)

[个人主页](https://liuchuanloong.github.io/)
